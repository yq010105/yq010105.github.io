<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="summary"><title>自己写的几个爬虫 | Yun.Qi</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/normalize.css/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.png"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.png"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/clipboard/dist/clipboard.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.js"></script><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.css"><meta name="generator" content="Hexo 4.2.0"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">自己写的几个爬虫</h1><a id="logo" href="/.">Yun.Qi</a><p class="summary">Note/Diary</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">自己写的几个爬虫</h1><div class="post-meta">2020-02-10<span> | </span><span class="category"><a href="/categories/%E6%8A%80%E6%9C%AF%E5%8A%9B/">技术力</a></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 2,067</span><span class="post-meta-item-text"> Words</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i><span class="post-count"> 12</span><span class="post-meta-item-text"> Minutes</span></span></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">目录</div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1-爬取-bilibili-每日排行榜数据"><span class="toc-text">1. 爬取 bilibili 每日排行榜数据</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-爬取-baidu-上搜到的图片-初级"><span class="toc-text">2. 爬取 baidu 上搜到的图片(初级)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-thumbURL"><span class="toc-text">2.1 thumbURL</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-objURL"><span class="toc-text">2.2 objURL</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-3-baidu-面向对象"><span class="toc-text">2.3 baidu 面向对象</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-4-baidu-more"><span class="toc-text">2.4 baidu_more</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-爬取-ins-上的图片-初级版"><span class="toc-text">3. 爬取 ins 上的图片(初级版)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-爬取-Wallhaven-上的图片"><span class="toc-text">4. 爬取 Wallhaven 上的图片</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#4-1-龟速爬取-只是用来爬了一下博客需要的图片-hhh"><span class="toc-text">4.1 龟速爬取,只是用来爬了一下博客需要的图片 hhh</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-2-多线程爬取"><span class="toc-text">4.2 多线程爬取</span></a></li></ol></li></ol></div></div><div class="post-content"><blockquote>
<p><strong>自己动手做的 python 爬虫</strong>   <a href="https://github.com/yq010105/spider_learn" target="_blank" rel="noopener" title="github">GitHub 链接</a><br>WARNING :逻辑混乱，语法不顺！！！</p>
</blockquote>
<a id="more"></a>

<h1 id="1-爬取-bilibili-每日排行榜数据"><a href="#1-爬取-bilibili-每日排行榜数据" class="headerlink" title="1. 爬取 bilibili 每日排行榜数据"></a>1. 爬取 bilibili 每日排行榜数据</h1><ul>
<li><strong>使用 XPath 爬取,并将数据保存到 csv 文件中</strong></li>
<li><strong>文件名使用该排行榜所在时间段</strong></li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> lxml.html</span><br><span class="line"></span><br><span class="line">url = <span class="string">'https://www.bilibili.com/ranking/'</span></span><br><span class="line">html = requests.get(url).content.decode()</span><br><span class="line"><span class="comment"># print(html)</span></span><br><span class="line"></span><br><span class="line">selector = lxml.html.fromstring(html)</span><br><span class="line"></span><br><span class="line">title = selector.xpath(<span class="string">'//*[@id="app"]/div[1]/div/div[1]/div[2]/div[3]/ul/li/div[2]/div[2]/a/text()'</span>)</span><br><span class="line"><span class="comment"># print(len(title))</span></span><br><span class="line"></span><br><span class="line">link = selector.xpath(<span class="string">'//*[@id="app"]/div[1]/div/div[1]/div[2]/div[3]/ul/li/div[2]/div[1]/a/@href'</span>)</span><br><span class="line"><span class="comment"># print(link[0])</span></span><br><span class="line"><span class="comment"># cover = selector.xpath('//*[@id="app"]/div[1]/div/div[1]/div[2]/div[3]/ul/li/div[2]/div[1]/a/div/img/@src')</span></span><br><span class="line"><span class="comment"># print(cover[0])</span></span><br><span class="line"></span><br><span class="line">up_name = selector.xpath(<span class="string">'//*[@id="app"]/div[1]/div/div[1]/div[2]/div[3]/ul/li/div[2]/div[2]/div[1]/a/span/text()'</span>)</span><br><span class="line"><span class="comment"># print(up_name[5])</span></span><br><span class="line">up_videoplay = selector.xpath(<span class="string">'//*[@id="app"]/div[1]/div/div[1]/div[2]/div[3]/ul/li/div[2]/div[2]/div[1]/span[1]/text()'</span>)</span><br><span class="line"></span><br><span class="line">time = selector.xpath(<span class="string">'//*[@id="app"]/div[1]/div/div[1]/div[2]/div[2]/div/span/text()'</span>)</span><br><span class="line">time_num = time[<span class="number">0</span>]</span><br><span class="line">str1 = time_num.replace(<span class="string">' 的数据综合得分，每日更新一次'</span>,<span class="string">''</span>)</span><br><span class="line">str2 = str1.replace(<span class="string">'统计所有投稿在 '</span>,<span class="string">''</span>)</span><br><span class="line">time_num2 = str2</span><br><span class="line"></span><br><span class="line">headers = [<span class="string">'up_name'</span>,<span class="string">'title'</span>,<span class="string">'link'</span>]</span><br><span class="line">rows = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    rows.append([up_name[i],title[i],link[i]])</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">f'<span class="subst">{time_num2}</span>.csv'</span>,<span class="string">'w'</span>,encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f_csv = csv.writer(f)</span><br><span class="line">    f_csv.writerow(headers)</span><br><span class="line">    f_csv.writerows(rows)</span><br></pre></td></tr></tbody></table></figure>

<ul>
<li><strong>csv 部分展示</strong><br><code>2020年02月07日 - 2020年02月10日</code></li>
</ul>
<p><img src="https://raw.githubusercontent.com/yq010105/Blog_images/master/img/bilibili_csv.png" alt="bilibili_csv"></p>
<h1 id="2-爬取-baidu-上搜到的图片-初级"><a href="#2-爬取-baidu-上搜到的图片-初级" class="headerlink" title="2. 爬取 baidu 上搜到的图片(初级)"></a>2. 爬取 baidu 上搜到的图片(初级)</h1><h2 id="2-1-thumbURL"><a href="#2-1-thumbURL" class="headerlink" title="2.1 thumbURL"></a>2.1 thumbURL</h2><ul>
<li><em>分辨率极低</em></li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download</span><span class="params">(html)</span>:</span></span><br><span class="line">    <span class="comment">#通过正则匹配</span></span><br><span class="line">    pic_url = re.findall(<span class="string">'"thumbURL":"(.*?)",'</span>,html, re.S)</span><br><span class="line">    i = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> pic_url:</span><br><span class="line">        print(<span class="string">"开始下载图片："</span>+key +<span class="string">"\r\n"</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            pic = requests.get(key, timeout=<span class="number">10</span>)</span><br><span class="line">        <span class="keyword">except</span> requests.exceptions.ConnectionError:</span><br><span class="line">            print(<span class="string">'图片无法下载'</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="comment">#保存图片路径</span></span><br><span class="line">        main_path=<span class="string">"E:/baidu/"</span> <span class="comment">#文件保存路径，如果不存在就会被重建</span></span><br><span class="line">        <span class="keyword">if</span>  <span class="keyword">not</span> os.path.exists(main_path):<span class="comment">#如果路径不存在</span></span><br><span class="line">            os.makedirs(main_path)</span><br><span class="line">        dir = <span class="string">"E:/baidu/"</span> + str(i) + <span class="string">'.jpg'</span></span><br><span class="line">        fp = open(dir, <span class="string">'wb'</span>)</span><br><span class="line">        fp.write(pic.content)</span><br><span class="line">        fp.close()</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">        url = <span class="string">'https://image.baidu.com/search/index?tn=baiduimage&amp;ipn=r&amp;ct=201326592&amp;cl=2&amp;lm=-1&amp;st=-1&amp;sf=1&amp;fmq=&amp;pv=&amp;ic=0&amp;nc=1&amp;z=&amp;se=1&amp;showtab=0&amp;fb=0&amp;width=&amp;height=&amp;face=0&amp;istype=2&amp;ie=utf-8&amp;fm=result&amp;pos=history&amp;word=siyueshinide'</span></span><br><span class="line">        result = requests.get(url)</span><br><span class="line">        download(result.text)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">        main()</span><br></pre></td></tr></tbody></table></figure>

<h2 id="2-2-objURL"><a href="#2-2-objURL" class="headerlink" title="2.2 objURL"></a>2.2 objURL</h2><p><em>分辨率较高，但有的图爬不了</em></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download</span><span class="params">(html)</span>:</span></span><br><span class="line">    <span class="comment">#通过正则匹配</span></span><br><span class="line">    pic_url = re.findall(<span class="string">'"objURL":"(.*?)",'</span>,html, re.S)</span><br><span class="line">    <span class="comment"># for pic_url_li in pic_url:</span></span><br><span class="line">        <span class="comment"># pic_url_js = '{'+'"link"'+':' +pic_url_li+'}'</span></span><br><span class="line">        <span class="comment"># pic_url_py = json.loads(pic_url_li)</span></span><br><span class="line">    <span class="comment"># print(pic_url)</span></span><br><span class="line">    <span class="comment"># exit()</span></span><br><span class="line">    i = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> pic_url:</span><br><span class="line">        print(<span class="string">"开始下载图片："</span>+key +<span class="string">"\r\n"</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            pic = requests.get(key, timeout=<span class="number">10</span>)</span><br><span class="line">        <span class="keyword">except</span> requests.exceptions.ConnectionError:</span><br><span class="line">            print(<span class="string">'图片无法下载'</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">except</span> requests.exceptions.ReadTimeout:</span><br><span class="line">            print(<span class="string">'requests.exceptions.ReadTimeout'</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="comment">#保存图片路径</span></span><br><span class="line">        main_path=<span class="string">"E:/baidu/"</span> <span class="comment">#文件保存路径，如果不存在就会被重建</span></span><br><span class="line">        <span class="keyword">if</span>  <span class="keyword">not</span> os.path.exists(main_path):<span class="comment">#如果路径不存在</span></span><br><span class="line">            os.makedirs(main_path)</span><br><span class="line">        dir = <span class="string">"E:/baidu/"</span> + str(i) + <span class="string">'.jpg'</span></span><br><span class="line">        fp = open(dir, <span class="string">'wb'</span>)</span><br><span class="line">        fp.write(pic.content)</span><br><span class="line">        fp.close()</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">        url = <span class="string">'https://image.baidu.com/search/index?tn=baiduimage&amp;ipn=r&amp;ct=201326592&amp;cl=2&amp;lm=-1&amp;st=-1&amp;sf=1&amp;fmq=&amp;pv=&amp;ic=0&amp;nc=1&amp;z=&amp;se=1&amp;showtab=0&amp;fb=0&amp;width=&amp;height=&amp;face=0&amp;istype=2&amp;ie=utf-8&amp;fm=result&amp;pos=history&amp;word=siyueshinide'</span></span><br><span class="line">        result = requests.get(url)</span><br><span class="line">        download(result.text)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">        main()</span><br></pre></td></tr></tbody></table></figure>

<h2 id="2-3-baidu-面向对象"><a href="#2-3-baidu-面向对象" class="headerlink" title="2.3 baidu 面向对象"></a>2.3 baidu 面向对象</h2><ul>
<li>输入想爬取的关键词，自动爬取(只能下 30 张)</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_id</span><span class="params">(search_id)</span>:</span></span><br><span class="line">    url = <span class="string">'http://image.baidu.com/search/index?tn=baiduimage&amp;ps=1&amp;ct=201326592&amp;lm=-1&amp;cl=2&amp;nc=1&amp;ie=utf-8&amp;word='</span> + search_id</span><br><span class="line">    <span class="keyword">return</span> url</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_obj</span><span class="params">()</span>:</span></span><br><span class="line">    url = get_id(search_id)</span><br><span class="line">    html = requests.get(url).content.decode()</span><br><span class="line">    obj_URL = re.findall(<span class="string">'"objURL":"(.*?)",'</span>,html,re.S)</span><br><span class="line">    <span class="keyword">return</span> obj_URL</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_pic</span><span class="params">()</span>:</span></span><br><span class="line">    obj_url = get_obj()</span><br><span class="line">    i = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> objurl <span class="keyword">in</span> obj_url:</span><br><span class="line">        print(<span class="string">'开始下载图片'</span>+<span class="string">'\t'</span>+<span class="string">'第'</span>+str(i)+<span class="string">'张'</span>)</span><br><span class="line">        <span class="keyword">try</span> :</span><br><span class="line">            pic = requests.get(objurl,timeout = <span class="number">10</span>)</span><br><span class="line">        <span class="keyword">except</span> requests.exceptions.ConnectionError:</span><br><span class="line">            print(<span class="string">'图片无法下载'</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">except</span> requests.exceptions.ReadTimeout:</span><br><span class="line">            print(<span class="string">'requests.exceptions.ReadTimeout'</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">global</span> search_id</span><br><span class="line">        main_path = <span class="string">r'E:\learn\py\git\spider\spider_learn\baidu\pic\\'</span> + search_id +<span class="string">'\\'</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(main_path):</span><br><span class="line">            os.makedirs(main_path)</span><br><span class="line">        dir = <span class="string">"E:\learn\py\git\spider\spider_learn\\baidu\pic\\"</span> +search_id +<span class="string">'\\'</span>+ search_id+ str(i) + <span class="string">'.jpg'</span></span><br><span class="line">        <span class="keyword">with</span> open(dir,<span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(pic.content)</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ ==<span class="string">'__main__'</span>:</span><br><span class="line">    search_id = input(<span class="string">'请输入要下载的内容:'</span>)</span><br><span class="line">    save_pic()</span><br></pre></td></tr></tbody></table></figure>

<h2 id="2-4-baidu-more"><a href="#2-4-baidu-more" class="headerlink" title="2.4 baidu_more"></a>2.4 baidu_more</h2><ul>
<li><strong>进一步升级，可以爬任意数量图片</strong></li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> multiprocessing.dummy <span class="keyword">import</span> Pool</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_urls</span><span class="params">(search_id)</span>:</span></span><br><span class="line">    total = (input(<span class="string">'请输入要几页----30张一页----：'</span>))</span><br><span class="line">    url = <span class="string">'http://image.baidu.com/search/index?tn=baiduimage&amp;ps=1&amp;ct=201326592&amp;lm=-1&amp;cl=2&amp;nc=1&amp;ie=utf-8&amp;word='</span> + search_id+ <span class="string">'&amp;pn='</span></span><br><span class="line">    t = <span class="number">0</span></span><br><span class="line">    URLS = []</span><br><span class="line">    <span class="keyword">while</span> t &lt; int(total)*<span class="number">30</span>:</span><br><span class="line">        URL = url + str(t)</span><br><span class="line">        t = t + <span class="number">30</span></span><br><span class="line">        URLS.append(URL)</span><br><span class="line">    <span class="keyword">return</span> URLS</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_obj</span><span class="params">(url)</span>:</span></span><br><span class="line">    html = requests.get(url).content.decode()</span><br><span class="line">    obj_URL = re.findall(<span class="string">'"objURL":"(.*?)",'</span>,html,re.S)</span><br><span class="line">    <span class="keyword">return</span> obj_URL</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_pic</span><span class="params">()</span>:</span></span><br><span class="line">    pool=Pool(<span class="number">5</span>)</span><br><span class="line">    objurls = pool.map(get_obj,URLS)</span><br><span class="line">    i = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> objurl <span class="keyword">in</span> objurls:</span><br><span class="line">        <span class="keyword">for</span> obj <span class="keyword">in</span> objurl:</span><br><span class="line">            print(<span class="string">'开始下载图片'</span>+<span class="string">'\t'</span>+<span class="string">'第'</span>+str(i)+<span class="string">'张'</span>)</span><br><span class="line">            <span class="keyword">try</span> :</span><br><span class="line">                pic = requests.get(obj,timeout = <span class="number">10</span>)</span><br><span class="line">            <span class="keyword">except</span> requests.exceptions.ConnectionError:</span><br><span class="line">                print(<span class="string">'图片无法下载'</span>)</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">except</span> requests.exceptions.ReadTimeout:</span><br><span class="line">                print(<span class="string">'requests.exceptions.ReadTimeout'</span>)</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">global</span> search_id</span><br><span class="line">            main_path = patha +<span class="string">'\\'</span> + search_id +<span class="string">'\\'</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(main_path):</span><br><span class="line">                os.makedirs(main_path)</span><br><span class="line">            dir = main_path + search_id+ str(i) + <span class="string">'.jpg'</span></span><br><span class="line">            <span class="keyword">with</span> open(dir,<span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">                f.write(pic.content)</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ ==<span class="string">'__main__'</span>:</span><br><span class="line">    search_id = input(<span class="string">'请输入要下载的内容:'</span>)</span><br><span class="line">    URLS = get_urls(search_id)</span><br><span class="line">    patha = input(<span class="string">'输入文件保存路径----示例:E:\\baidu----:'</span>)</span><br><span class="line">    save_pic()</span><br></pre></td></tr></tbody></table></figure>

<h1 id="3-爬取-ins-上的图片-初级版"><a href="#3-爬取-ins-上的图片-初级版" class="headerlink" title="3. 爬取 ins 上的图片(初级版)"></a>3. 爬取 ins 上的图片(初级版)</h1><ul>
<li><em>分辨率低</em></li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> lxml.html</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取src</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_src</span><span class="params">()</span>:</span></span><br><span class="line">    url = <span class="string">'https://www.instagram.com/baaaakuuuu'</span></span><br><span class="line">    html = requests.get(url).content.decode()</span><br><span class="line">    selector = lxml.html.fromstring(html)</span><br><span class="line">    script = selector.xpath(<span class="string">'/html/body/script[1]/text()'</span>)[<span class="number">0</span>].strip()</span><br><span class="line">    <span class="comment"># print(script)</span></span><br><span class="line">    <span class="comment"># print(type(script))       #str</span></span><br><span class="line">    <span class="comment"># exit()</span></span><br><span class="line">    <span class="comment"># for script_in in script :</span></span><br><span class="line">        <span class="comment"># try:</span></span><br><span class="line">        <span class="comment">#     script_dic = json.loads(script_in)</span></span><br><span class="line">        <span class="comment"># print(script_dic)</span></span><br><span class="line">    src = re.findall(<span class="string">r'"thumbnail_resources":\[(.*?)\]'</span>,script,re.S)</span><br><span class="line">    <span class="comment"># print(src[0]) #str</span></span><br><span class="line">    <span class="comment"># print(type(src[0]))</span></span><br><span class="line">    <span class="comment"># exit()</span></span><br><span class="line">    <span class="keyword">return</span> src</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取图片链接</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_picurl</span><span class="params">()</span>:</span></span><br><span class="line">    src = get_src()</span><br><span class="line">    <span class="comment"># print(src)</span></span><br><span class="line">    <span class="comment"># exit()</span></span><br><span class="line">    pic_url_lst = []</span><br><span class="line">    <span class="keyword">for</span> src_ls <span class="keyword">in</span> src :         <span class="comment">#"config_height":480},{ ... ,"config_width":640,"config_height":640}</span></span><br><span class="line">        thumb = re.findall(<span class="string">r'"config_height":480},{(.*?),"config_width":640,"config_height":640}'</span>,src_ls)[<span class="number">0</span>]</span><br><span class="line">        thumb_json = <span class="string">'{'</span> + thumb + <span class="string">'}'</span></span><br><span class="line">        <span class="comment"># print(thumb_json)</span></span><br><span class="line">        <span class="comment"># exit()</span></span><br><span class="line">        thumb_py = json.loads(thumb_json)</span><br><span class="line">        pic_url = thumb_py[<span class="string">'src'</span>]</span><br><span class="line">        <span class="comment"># print(pic_url)</span></span><br><span class="line">        <span class="comment"># exit()</span></span><br><span class="line">        pic_url_lst.append(pic_url)</span><br><span class="line">    <span class="comment"># print(pic_url_lst)</span></span><br><span class="line">    <span class="comment"># exit()</span></span><br><span class="line">    <span class="keyword">return</span> pic_url_lst</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将图片链接保存</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_pic</span><span class="params">()</span>:</span></span><br><span class="line">    pic_url_lst = get_picurl()</span><br><span class="line">    i = <span class="number">1</span></span><br><span class="line">    <span class="comment"># print(pic_url_lst)</span></span><br><span class="line">    <span class="comment"># exit()</span></span><br><span class="line">    <span class="keyword">for</span> pic_con <span class="keyword">in</span> pic_url_lst:</span><br><span class="line">        <span class="comment"># print(pic_con)</span></span><br><span class="line">        <span class="comment"># exit()</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            pic = requests.get(pic_con, timeout=<span class="number">10</span>)</span><br><span class="line">            main_path = <span class="string">'E:/ins/'</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(main_path):</span><br><span class="line">                os.makedirs(main_path)</span><br><span class="line">            path = <span class="string">'E:/ins/'</span> + <span class="string">'baku'</span> + str(i) + <span class="string">'.jpg'</span></span><br><span class="line">            <span class="keyword">with</span> open(path,<span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">                f.write(pic.content)</span><br><span class="line">                print(<span class="string">f'第<span class="subst">{i}</span>张已下载'</span>)</span><br><span class="line">            i +=<span class="number">1</span></span><br><span class="line">        <span class="keyword">except</span> requests.exceptions.ConnectionError:        <span class="comment">#requests.exceptions.ConnectionError</span></span><br><span class="line">            print(<span class="string">'图片无法下载'</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">save_pic()</span><br></pre></td></tr></tbody></table></figure>

<h1 id="4-爬取-Wallhaven-上的图片"><a href="#4-爬取-Wallhaven-上的图片" class="headerlink" title="4. 爬取 Wallhaven 上的图片"></a>4. 爬取 Wallhaven 上的图片</h1><h2 id="4-1-龟速爬取-只是用来爬了一下博客需要的图片-hhh"><a href="#4-1-龟速爬取-只是用来爬了一下博客需要的图片-hhh" class="headerlink" title="4.1 龟速爬取,只是用来爬了一下博客需要的图片 hhh"></a>4.1 龟速爬取,只是用来爬了一下博客需要的图片 hhh</h2><p><em>爬取速度慢，要等半天才能开始保存文件，应该是我代码结构的问题，以后再做优化</em></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> lxml.html</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">headers = {<span class="string">"User-Agent"</span>:<span class="string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.116 Safari/537.36"</span>}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_url</span><span class="params">()</span>:</span></span><br><span class="line">    pages = input(<span class="string">'输入页数：'</span>)</span><br><span class="line">    <span class="comment"># pages = '1'</span></span><br><span class="line">    url_pics = []</span><br><span class="line">    page = <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> page &lt;= int(pages):</span><br><span class="line">        url = <span class="string">'https://wallhaven.cc/search?categories=010&amp;purity=100&amp;resolutions=1280x800&amp;sorting=relevance&amp;order=desc&amp;page='</span> + str(page)</span><br><span class="line">        html = requests.get(url,headers = headers).content.decode()</span><br><span class="line">    <span class="comment"># print(html)</span></span><br><span class="line">    <span class="comment"># exit()</span></span><br><span class="line">        selector = lxml.html.fromstring(html)</span><br><span class="line"></span><br><span class="line">        url_pic = selector.xpath(<span class="string">'//*[@id="thumbs"]/section/ul/li/figure/a/@href'</span>)</span><br><span class="line">        url_pics.append(url_pic)</span><br><span class="line">        page += <span class="number">1</span></span><br><span class="line">    print(<span class="string">'得到了内层url'</span>)</span><br><span class="line">    <span class="keyword">return</span> url_pics</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_pic</span><span class="params">()</span>:</span></span><br><span class="line">    url_pics = get_url()</span><br><span class="line">    img_urls = []</span><br><span class="line">    <span class="keyword">for</span> urlst <span class="keyword">in</span> url_pics:</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> urlst:</span><br><span class="line">            htmlp = requests.get(url,headers = headers).content.decode()</span><br><span class="line">            <span class="comment"># print(htmlp)</span></span><br><span class="line">            <span class="comment"># exit()</span></span><br><span class="line">            img_url = re.findall(<span class="string">r'"wallpaper" src="(.*?)"'</span>,htmlp,re.S)[<span class="number">0</span>]</span><br><span class="line">            img_urls.append(img_url)</span><br><span class="line">    print(<span class="string">'得到图片的url'</span>)</span><br><span class="line">    <span class="keyword">return</span> img_urls</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_img</span><span class="params">(imgurl_list)</span>:</span></span><br><span class="line">    i = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> imgurl_list:</span><br><span class="line">        print(<span class="string">'开始下载图片'</span>+<span class="string">'\t'</span>+<span class="string">'第'</span>+str(i)+<span class="string">'张'</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            pic = requests.get(url, timeout=<span class="number">10</span>)</span><br><span class="line">        <span class="keyword">except</span> requests.exceptions.ConnectionError:</span><br><span class="line">            print(<span class="string">'图片无法下载'</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">except</span> requests.exceptions.ReadTimeout:</span><br><span class="line">            print(<span class="string">'requests.exceptions.ReadTimeout'</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        main_path = <span class="string">r'E:\\wallhaven\\'</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(main_path):</span><br><span class="line">            os.makedirs(main_path)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        dir = <span class="string">'E:\\wallhaven\\'</span> + str(i) +<span class="string">'.jpg'</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> open(dir, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(pic.content)</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    imgurl_list = get_pic()</span><br><span class="line">    get_img(imgurl_list)</span><br></pre></td></tr></tbody></table></figure>

<h2 id="4-2-多线程爬取"><a href="#4-2-多线程爬取" class="headerlink" title="4.2 多线程爬取"></a>4.2 多线程爬取</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">遇到了一个bug，等到bug解决再写上来</span><br></pre></td></tr></tbody></table></figure><script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script></div><div class="tags"><a href="/tags/Python/"><i class="fa fa-tag"></i>Python</a><a href="/tags/Spider/"><i class="fa fa-tag"></i>Spider</a></div><div class="post-nav"><a class="pre" href="/2020/02/11/python-format/">Python中format函数的学习</a><a class="next" href="/2020/02/09/note-python/">Python-Note</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/%E5%89%8D%E7%AB%AF/" style="font-size: 15px;">前端</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/Compete/" style="font-size: 15px;">Compete</a> <a href="/tags/Bilibili/" style="font-size: 15px;">Bilibili</a> <a href="/tags/%E5%8D%95%E7%89%87%E6%9C%BA/" style="font-size: 15px;">单片机</a> <a href="/tags/Hexo/" style="font-size: 15px;">Hexo</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/Note/" style="font-size: 15px;">Note</a> <a href="/tags/Spider/" style="font-size: 15px;">Spider</a> <a href="/tags/Windows/" style="font-size: 15px;">Windows</a> <a href="/tags/Markdown/" style="font-size: 15px;">Markdown</a> <a href="/tags/Server/" style="font-size: 15px;">Server</a> <a href="/tags/Jsoup/" style="font-size: 15px;">Jsoup</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/VB/" style="font-size: 15px;">VB</a> <a href="/tags/Lua/" style="font-size: 15px;">Lua</a> <a href="/tags/C/" style="font-size: 15px;">C#</a> <a href="/tags/Questions/" style="font-size: 15px;">Questions</a> <a href="/tags/Github/" style="font-size: 15px;">Github</a> <a href="/tags/Source/" style="font-size: 15px;">Source</a> <a href="/tags/Api/" style="font-size: 15px;">Api</a> <a href="/tags/Life/" style="font-size: 15px;">Life</a> <a href="/tags/Imagination/" style="font-size: 15px;">Imagination</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AD%A6%E4%B9%A0%E5%8A%9B/">学习力</a><span class="category-list-count">34</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%83%B3%E8%B1%A1%E5%8A%9B/">想象力</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E5%8A%9B/">技术力</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%97%A0%E5%8A%9B/">无力</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%B5%84%E6%BA%90%E5%8A%9B/">资源力</a><span class="category-list-count">3</span></li></ul></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2020 <a href="/." rel="nofollow">Yun.Qi.</a> | Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a> | Theme by<a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Maupassant</a><br/><span class="footer-birthday-text">Birthday</span><span class="footer-birthday-date">2020/02/04</span></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.css"><link rel="stylesheet" type="text/css" href="/css/search.css?v=0.0.0"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/copycode.js" successtext="Copy Successed!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>